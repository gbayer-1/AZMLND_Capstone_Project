{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning using HyperDrive\n",
    "\n",
    "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1635337412084
    }
   },
   "outputs": [],
   "source": [
    "# setup workspace\n",
    "from azureml.core import Workspace, Experiment\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.exceptions import ComputeTargetException\n",
    "# load dataset\n",
    "from train import read_data\n",
    "# Hyperdrive Run\n",
    "from azureml.train.hyperdrive.policy import BanditPolicy\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azureml.train.hyperdrive.parameter_expressions import uniform, choice, randint\n",
    "from azureml.widgets import RunDetails\n",
    "# Deploy model\n",
    "from azureml.core import Model, Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import LocalWebservice, AciWebservice\n",
    "# consume model\n",
    "import json, requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset I'm using for this project is the Heart Failure Prediction Dataset from kaggle.\n",
    "\n",
    "fedesoriano. (September 2021). Heart Failure Prediction Dataset. Retrieved [2021-10-18] from https://www.kaggle.com/fedesoriano/heart-failure-prediction.\n",
    "\n",
    "The task with this dataset is a classification task to predict whether a person will develop a heart disease with a set of 11 diagnostic features.\n",
    "\n",
    "A detailed description of the dataset can be found in `automl.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup workspace and experiment\n",
    "\n",
    "Use Workspace.from_config() to get the workspace configuration in the VM.\n",
    "Set up an experiment with the name \"heart-failure-experiment\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1635337417037
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: quick-starts-ws-162187\n",
      "Azure region: southcentralus\n",
      "Subscription id: d7f39349-a66b-446e-aba6-0053c2cf1c11\n",
      "Resource group: aml-quickstarts-162187\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "\n",
    "# print some information about the workspace\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
    "\n",
    "# choose a name for experiment\n",
    "experiment_name = 'heart-failure-experiment'\n",
    "\n",
    "experiment=Experiment(ws, experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a cluster\n",
    "\n",
    "Reuse the AutoML cluster or create a new one, if it doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1635172457525
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it!\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "cluster_name = \"expcluster\"\n",
    "\n",
    "# Use existing cluster, if it exists\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name = cluster_name)\n",
    "    print('Found existing cluster, use it!')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_DS12_v2',\n",
    "                                                          max_nodes=6, min_nodes=1)\n",
    "    compute_target = ComputeTarget.create(workspace=ws, name=cluster_name, provisioning_configuration=compute_config)\n",
    "compute_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset\n",
    "Reuse the dataset from the AutoML run or upload it, if it doesn't exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1635337446536
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading ./data/heart.csv\n",
      "Uploaded ./data/heart.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n",
      "Validating arguments.\n",
      "Arguments validated.\n",
      "Successfully obtained datastore reference and path.\n",
      "Uploading file to managed-dataset/2836e50e-adee-43bf-b8a7-44fb85bf2a8e/\n",
      "Successfully uploaded file to datastore.\n",
      "Creating and registering a new dataset.\n",
      "Successfully created and registered a new dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Method register_pandas_dataframe: This is an experimental method, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ST_Slope</th>\n",
       "      <th>HeartDisease</th>\n",
       "      <th>ChestPainType_ASY</th>\n",
       "      <th>ChestPainType_ATA</th>\n",
       "      <th>ChestPainType_NAP</th>\n",
       "      <th>ChestPainType_TA</th>\n",
       "      <th>RestingECG_LVH</th>\n",
       "      <th>RestingECG_Normal</th>\n",
       "      <th>RestingECG_ST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>918.000000</td>\n",
       "      <td>918.000000</td>\n",
       "      <td>918.000000</td>\n",
       "      <td>918.000000</td>\n",
       "      <td>918.000000</td>\n",
       "      <td>918.000000</td>\n",
       "      <td>918.000000</td>\n",
       "      <td>918.000000</td>\n",
       "      <td>918.000000</td>\n",
       "      <td>918.000000</td>\n",
       "      <td>918.000000</td>\n",
       "      <td>918.000000</td>\n",
       "      <td>918.000000</td>\n",
       "      <td>918.000000</td>\n",
       "      <td>918.000000</td>\n",
       "      <td>918.000000</td>\n",
       "      <td>918.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>53.510893</td>\n",
       "      <td>0.789760</td>\n",
       "      <td>132.396514</td>\n",
       "      <td>198.799564</td>\n",
       "      <td>0.233115</td>\n",
       "      <td>136.809368</td>\n",
       "      <td>0.404139</td>\n",
       "      <td>0.887364</td>\n",
       "      <td>0.361656</td>\n",
       "      <td>0.553377</td>\n",
       "      <td>0.540305</td>\n",
       "      <td>0.188453</td>\n",
       "      <td>0.221133</td>\n",
       "      <td>0.050109</td>\n",
       "      <td>0.204793</td>\n",
       "      <td>0.601307</td>\n",
       "      <td>0.193900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.432617</td>\n",
       "      <td>0.407701</td>\n",
       "      <td>18.514154</td>\n",
       "      <td>109.384145</td>\n",
       "      <td>0.423046</td>\n",
       "      <td>25.460334</td>\n",
       "      <td>0.490992</td>\n",
       "      <td>1.066570</td>\n",
       "      <td>0.607056</td>\n",
       "      <td>0.497414</td>\n",
       "      <td>0.498645</td>\n",
       "      <td>0.391287</td>\n",
       "      <td>0.415236</td>\n",
       "      <td>0.218289</td>\n",
       "      <td>0.403770</td>\n",
       "      <td>0.489896</td>\n",
       "      <td>0.395567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.600000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>173.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>603.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age         Sex   RestingBP  Cholesterol   FastingBS  \\\n",
       "count  918.000000  918.000000  918.000000   918.000000  918.000000   \n",
       "mean    53.510893    0.789760  132.396514   198.799564    0.233115   \n",
       "std      9.432617    0.407701   18.514154   109.384145    0.423046   \n",
       "min     28.000000    0.000000    0.000000     0.000000    0.000000   \n",
       "25%     47.000000    1.000000  120.000000   173.250000    0.000000   \n",
       "50%     54.000000    1.000000  130.000000   223.000000    0.000000   \n",
       "75%     60.000000    1.000000  140.000000   267.000000    0.000000   \n",
       "max     77.000000    1.000000  200.000000   603.000000    1.000000   \n",
       "\n",
       "            MaxHR  ExerciseAngina     Oldpeak    ST_Slope  HeartDisease  \\\n",
       "count  918.000000      918.000000  918.000000  918.000000    918.000000   \n",
       "mean   136.809368        0.404139    0.887364    0.361656      0.553377   \n",
       "std     25.460334        0.490992    1.066570    0.607056      0.497414   \n",
       "min     60.000000        0.000000   -2.600000   -1.000000      0.000000   \n",
       "25%    120.000000        0.000000    0.000000    0.000000      0.000000   \n",
       "50%    138.000000        0.000000    0.600000    0.000000      1.000000   \n",
       "75%    156.000000        1.000000    1.500000    1.000000      1.000000   \n",
       "max    202.000000        1.000000    6.200000    1.000000      1.000000   \n",
       "\n",
       "       ChestPainType_ASY  ChestPainType_ATA  ChestPainType_NAP  \\\n",
       "count         918.000000         918.000000         918.000000   \n",
       "mean            0.540305           0.188453           0.221133   \n",
       "std             0.498645           0.391287           0.415236   \n",
       "min             0.000000           0.000000           0.000000   \n",
       "25%             0.000000           0.000000           0.000000   \n",
       "50%             1.000000           0.000000           0.000000   \n",
       "75%             1.000000           0.000000           0.000000   \n",
       "max             1.000000           1.000000           1.000000   \n",
       "\n",
       "       ChestPainType_TA  RestingECG_LVH  RestingECG_Normal  RestingECG_ST  \n",
       "count        918.000000      918.000000         918.000000     918.000000  \n",
       "mean           0.050109        0.204793           0.601307       0.193900  \n",
       "std            0.218289        0.403770           0.489896       0.395567  \n",
       "min            0.000000        0.000000           0.000000       0.000000  \n",
       "25%            0.000000        0.000000           0.000000       0.000000  \n",
       "50%            0.000000        0.000000           1.000000       0.000000  \n",
       "75%            0.000000        0.000000           1.000000       0.000000  \n",
       "max            1.000000        1.000000           1.000000       1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=read_data()\n",
    "df = dataset.to_pandas_dataframe()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598531923519
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Hyperdrive Configuration\n",
    "\n",
    "TODO: Explain the model you are using and the reason for chosing the different hyperparameters, termination policy and config settings.\n",
    "\n",
    "#### Model\n",
    "I'm using a RandomForestClassifier model from sklearn for this task. The model training is defined in the `train.py` script.\n",
    "I'm tuning three parameters of this model, using a random parameter sampling:\n",
    "- `n_estimators`: the number of trees in the RandomForest model. The tuning algorithm will use random integers up to 10000.\n",
    "- `max_depth`: the maximum depth of a tree. The depth will be chosen from $[10, 100, 1000, 5000]$\n",
    "- `min_samples_split`: The minimum number of samples required to split an internal node. Here the input will be a random integer up to 50. [Attention] The input for this parameter should be greater than 2! Any run with a lower number will fail.\n",
    "\n",
    "For early termination I use a Banditpolicy with a slack factore of $0.1$. This means any model, that is more than 10% worse in regard to the primary metric than the current best model is terminated.\n",
    "\n",
    "The HyperDrive experiment will run on the above created cluster `expcluster`. To run the training script, some packages (`pandas`, `skl2onnx`, `azureml-defaults`) need to be installed on the cluster and `python`and `scikit-learn` should be accessible. This I defined in the environment script `conda_environment.yml`.\n",
    "\n",
    "The primary metric, that should be maximized is Accuracy. In `train.py` I also log other metrics for the model. The maximum number of runs for this Experiment is $50$, and 5 iterations can be run in parallel (`max_concurrent_runs`).\n",
    "\n",
    "The models will be saved in `pkl` and `onnx` format in the outputs\\ folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "gather": {
     "logged": 1635340357920
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "early_termination_policy = BanditPolicy(evaluation_interval=2, slack_factor=0.1)\n",
    "\n",
    "param_sampling = RandomParameterSampling({\"--n_estimators\": randint(10000),\n",
    "    \"--max_depth\": choice(10, 100, 1000, 5000),\n",
    "    \"--min_samples_split\": randint(50)})\n",
    "\n",
    "from azureml.core import Environment\n",
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "env = Environment.from_conda_specification(name = 'env', file_path = './envs/conda_environment.yml')\n",
    "\n",
    "src = ScriptRunConfig(source_directory = \"./\",\n",
    "    script = \"train.py\",\n",
    "    compute_target = \"expcluster\",\n",
    "    environment = env)\n",
    "\n",
    "hyperdrive_run_config = HyperDriveConfig(run_config=src,\n",
    "    hyperparameter_sampling=param_sampling,\n",
    "    policy=early_termination_policy,\n",
    "    primary_metric_name=\"Accuracy\",\n",
    "    primary_metric_goal= PrimaryMetricGoal.MAXIMIZE,\n",
    "    max_total_runs=50,\n",
    "    max_concurrent_runs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1635171726711
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "hyperdrive_run = experiment.submit(hyperdrive_run_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598544898497
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Run Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1635171727797
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "RunDetails(hyperdrive_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
    "\n",
    "Some hyperdrive runs failed, since the input for `min_samples_split` was $0$ or $1$. This was expected, since the function `randint(59)` chooses a random integer between $[0,50]$.\n",
    "The models accuracy is higher with low values for this parameter, since the trees can be much deeper.\n",
    "A high number of estimators do not necessarily result in a better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1635172310442
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "hyperdrive_run.get_children_sorted_by_primary_metric()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model\n",
    "\n",
    "TODO: In the cell below, get the best model from the hyperdrive experiments and display all the properties of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1635172319595
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "best_hyperdrive_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
    "print(\"best run details: \", best_hyperdrive_run.get_details())\n",
    "print(\"best run metrics :\", best_hyperdrive_run.get_metrics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "gather": {
     "logged": 1635172404915
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from outputs/hyperdrive_model.onnx to ./model/hyperdrive_model.onnx ...\n"
     ]
    }
   ],
   "source": [
    "for f in best_hyperdrive_run.get_file_names():\n",
    "    if f.startswith('outputs/hyperdrive_model.onnx'):\n",
    "        output_file_path = os.path.join('./hyperdrive_model', 'hyperdrive_model.onnx')\n",
    "        print('Downloading from {} to {} ...'.format(f, output_file_path))\n",
    "        best_hyperdrive_run.download_file(name=f, output_file_path=output_file_path)\n",
    "    elif f.startswith('outputs/model'):\n",
    "        output_file_path = os.path.join('./hyperdrive_model', 'hyperdrive_model.pkl')\n",
    "        print('Downloading from {} to {} ...'.format(f, output_file_path))\n",
    "        best_hyperdrive_run.download_file(name=f, output_file_path=output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Model Deployment\n",
    "\n",
    "### Register Model\n",
    "I'm registering the saved `onnx` model for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gather": {
     "logged": 1635337469503
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model hyperdrive_model\n"
     ]
    }
   ],
   "source": [
    "# register the onnx model\n",
    "description = \"HyperDrive run heart-failure classification model\"\n",
    "\n",
    "model = Model.register(workspace=ws,\n",
    "    model_name=\"hyperdrive_model\",\n",
    "    model_path='./hyperdrive_model/hyperdrive_model.onnx',\n",
    "    model_framework=Model.Framework.ONNX,\n",
    "    model_framework_version='1.3',\n",
    "    description=description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Deployment\n",
    "First I deploy the model as a LocalWebservice for debugging purposes.\n",
    "\n",
    "I created the environment file for the webservice using the `write_env_file.py`. To run the `onnx` model, `onnxruntime` needs to be installed on the server.\n",
    "The scoring script for the `onnx` model is `score_onnx_model_version2.py`.\n",
    "In this script I defined an `init()` function to load the model into an `onnxruntime.InferenceSession` object. The `run()` function passes the input values to the model and returns its prediction. The input in the model is an array, but I find it more user friendly to give the input in the shape of a pandas dataframe. Therefore the webservice expects a `PandasParameterType`, which I then convert into the array for the model.\n",
    "I also used the inference_schema and decorator functions to create a swagger.json for the Webservice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "gather": {
     "logged": 1635339671486
    }
   },
   "outputs": [],
   "source": [
    "service_name = 'heart-failure-hyperdrive-service'\n",
    "\n",
    "env = Environment.from_conda_specification(name=\"hyperdrive_env\", file_path='./hyperdrive_model/hyperdrive_env.yml')\n",
    "inference_config = InferenceConfig(entry_script='hyperdrive_model/score_onnx_model_version2.py',\n",
    "                                   environment=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "gather": {
     "logged": 1635339582007
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model hyperdrive_model:1 to /tmp/azureml_liaa_aoz/hyperdrive_model/1\n",
      "Generating Docker build context.\n",
      "Package creation Succeeded\n",
      "Logging into Docker registry dc7c18e998184205acf38658cc51f079.azurecr.io\n",
      "Logging into Docker registry dc7c18e998184205acf38658cc51f079.azurecr.io\n",
      "Building Docker image from Dockerfile...\n",
      "Step 1/5 : FROM dc7c18e998184205acf38658cc51f079.azurecr.io/azureml/azureml_43f212a02480d80122155ef1231227f6\n",
      " ---> 5a0df70074d4\n",
      "Step 2/5 : COPY azureml-app /var/azureml-app\n",
      " ---> 73e29150c363\n",
      "Step 3/5 : RUN mkdir -p '/var/azureml-app' && echo eyJhY2NvdW50Q29udGV4dCI6eyJzdWJzY3JpcHRpb25JZCI6ImQ3ZjM5MzQ5LWE2NmItNDQ2ZS1hYmE2LTAwNTNjMmNmMWMxMSIsInJlc291cmNlR3JvdXBOYW1lIjoiYW1sLXF1aWNrc3RhcnRzLTE2MjE4NyIsImFjY291bnROYW1lIjoicXVpY2stc3RhcnRzLXdzLTE2MjE4NyIsIndvcmtzcGFjZUlkIjoiZGM3YzE4ZTktOTgxOC00MjA1LWFjZjMtODY1OGNjNTFmMDc5In0sIm1vZGVscyI6e30sIm1vZGVsc0luZm8iOnt9fQ== | base64 --decode > /var/azureml-app/model_config_map.json\n",
      " ---> Running in 08f7165465b0\n",
      " ---> d28f43e539b6\n",
      "Step 4/5 : RUN mv '/var/azureml-app/tmpuhsnrj0a.py' /var/azureml-app/main.py\n",
      " ---> Running in 13950ad1118c\n",
      " ---> 33193ac9f4be\n",
      "Step 5/5 : CMD [\"runsvdir\",\"/var/runit\"]\n",
      " ---> Running in 8d381f573eb5\n",
      " ---> 3615c87900e6\n",
      "Successfully built 3615c87900e6\n",
      "Successfully tagged test-service:latest\n",
      "Container (name:goofy_rubin, id:ff72c04adf57a9c0f86331d88c6ed1a95adbac7f4e8c0614cd5acab15d17802c) cannot be killed.\n",
      "Container has been successfully cleaned up.\n",
      "Image sha256:360f23f711a0562794cd7bf37297fa4330bd28483216d9ac0d8e10ffec07b890 successfully removed.\n",
      "Starting Docker container...\n",
      "Docker container running.\n",
      "Checking container health...\n",
      "Local webservice is running at http://localhost:6789\n"
     ]
    }
   ],
   "source": [
    "# deploy to local for debugging\n",
    "deployment_config = LocalWebservice.deploy_configuration(port=6789)\n",
    "test_service = Model.deploy(\n",
    "    ws,\n",
    "    name='test-service',\n",
    "    models=[model],\n",
    "    inference_config=inference_config,\n",
    "    deployment_config=deployment_config,\n",
    "    overwrite=True\n",
    ")\n",
    "test_service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the swagger.json from the LocalWebservice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "gather": {
     "logged": 1635339709383
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"swagger\": \"2.0\", \"info\": {\"title\": \"ML service\", \"description\": \"API specification for the Azure Machine Learning service ML service\", \"version\": \"1.0\"}, \"schemes\": [\"https\"], \"consumes\": [\"application/json\"], \"produces\": [\"application/json\"], \"securityDefinitions\": {\"Bearer\": {\"type\": \"apiKey\", \"name\": \"Authorization\", \"in\": \"header\", \"description\": \"For example: Bearer abc123\"}}, \"paths\": {\"/\": {\"get\": {\"operationId\": \"ServiceHealthCheck\", \"description\": \"Simple health check endpoint to ensure the service is up at any given point.\", \"responses\": {\"200\": {\"description\": \"If service is up and running, this response will be returned with the content \\'Healthy\\'\", \"schema\": {\"type\": \"string\"}, \"examples\": {\"application/json\": \"Healthy\"}}, \"default\": {\"description\": \"The service failed to execute due to an error.\", \"schema\": {\"$ref\": \"#/definitions/ErrorResponse\"}}}}}, \"/score\": {\"post\": {\"operationId\": \"RunMLService\", \"description\": \"Run web service\\'s model and get the prediction output\", \"security\": [{\"Bearer\": []}], \"parameters\": [{\"name\": \"serviceInputPayload\", \"in\": \"body\", \"description\": \"The input payload for executing the real-time machine learning service.\", \"schema\": {\"$ref\": \"#/definitions/ServiceInput\"}}], \"responses\": {\"200\": {\"description\": \"The service processed the input correctly and provided a result prediction, if applicable.\", \"schema\": {\"$ref\": \"#/definitions/ServiceOutput\"}}, \"default\": {\"description\": \"The service failed to execute due to an error.\", \"schema\": {\"$ref\": \"#/definitions/ErrorResponse\"}}}}}}, \"definitions\": {\"ServiceInput\": {\"type\": \"object\", \"properties\": {\"Inputs\": {\"type\": \"array\", \"items\": {\"type\": \"array\", \"items\": {\"type\": \"object\", \"required\": [\"Age\", \"Sex\", \"RestingBP\", \"Cholesterol\", \"FastingBS\", \"MaxHR\", \"ExerciseAngina\", \"Oldpeak\", \"ST_Slope\", \"ChestPainType_ASY\", \"ChestPainType_ATA\", \"ChestPainType_NAP\", \"ChestPainType_TA\", \"RestingECG_LVH\", \"RestingECG_Normal\", \"RestingECG_ST\"], \"properties\": {\"Age\": {\"type\": \"integer\", \"format\": \"int64\"}, \"Sex\": {\"type\": \"integer\", \"format\": \"int64\"}, \"RestingBP\": {\"type\": \"integer\", \"format\": \"int64\"}, \"Cholesterol\": {\"type\": \"integer\", \"format\": \"int64\"}, \"FastingBS\": {\"type\": \"integer\", \"format\": \"int64\"}, \"MaxHR\": {\"type\": \"integer\", \"format\": \"int64\"}, \"ExerciseAngina\": {\"type\": \"integer\", \"format\": \"int64\"}, \"Oldpeak\": {\"type\": \"number\", \"format\": \"double\"}, \"ST_Slope\": {\"type\": \"integer\", \"format\": \"int64\"}, \"ChestPainType_ASY\": {\"type\": \"integer\", \"format\": \"int64\"}, \"ChestPainType_ATA\": {\"type\": \"integer\", \"format\": \"int64\"}, \"ChestPainType_NAP\": {\"type\": \"integer\", \"format\": \"int64\"}, \"ChestPainType_TA\": {\"type\": \"integer\", \"format\": \"int64\"}, \"RestingECG_LVH\": {\"type\": \"integer\", \"format\": \"int64\"}, \"RestingECG_Normal\": {\"type\": \"integer\", \"format\": \"int64\"}, \"RestingECG_ST\": {\"type\": \"integer\", \"format\": \"int64\"}}}}}}, \"example\": {\"Inputs\": [[{\"Age\": 0, \"Sex\": 0, \"RestingBP\": 0, \"Cholesterol\": 0, \"FastingBS\": 0, \"MaxHR\": 0, \"ExerciseAngina\": 0, \"Oldpeak\": 0.0, \"ST_Slope\": 0, \"ChestPainType_ASY\": 0, \"ChestPainType_ATA\": 0, \"ChestPainType_NAP\": 0, \"ChestPainType_TA\": 0, \"RestingECG_LVH\": 0, \"RestingECG_Normal\": 0, \"RestingECG_ST\": 0}]]}}, \"ServiceOutput\": {\"type\": \"object\", \"required\": [\"Results\"], \"properties\": {\"Results\": {\"type\": \"array\", \"items\": {\"type\": \"integer\", \"format\": \"int64\"}}}, \"example\": {\"Results\": [0]}}, \"ErrorResponse\": {\"type\": \"object\", \"properties\": {\"status_code\": {\"type\": \"integer\", \"format\": \"int32\"}, \"message\": {\"type\": \"string\"}}}}}'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = requests.get(test_service.swagger_uri)\n",
    "r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "gather": {
     "logged": 1635339813313
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Inputs': [[{'Age': 40, 'Sex': 1, 'RestingBP': 140, 'Cholesterol': 289, 'FastingBS': 0, 'MaxHR': 172, 'ExerciseAngina': 0, 'Oldpeak': 0.0, 'ST_Slope': 1, 'ChestPainType_ASY': 0, 'ChestPainType_ATA': 1, 'ChestPainType_NAP': 0, 'ChestPainType_TA': 0, 'RestingECG_LVH': 0, 'RestingECG_Normal': 1, 'RestingECG_ST': 0}]]}\n"
     ]
    }
   ],
   "source": [
    "# get some testdata to send a request\n",
    "data = df.head(1).drop(\"HeartDisease\", axis=1).to_dict(orient=\"records\")\n",
    "body = {\"Inputs\": [data],}\n",
    "print(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "gather": {
     "logged": 1635339823361
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "# test against local deploymenz\n",
    "uri = test_service.scoring_uri\n",
    "requests.get(\"http://localhost:6789\")\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "response = requests.post(uri, data=json.dumps(body), headers=headers)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "gather": {
     "logged": 1635339478820
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container (name:strange_booth, id:bf601216c7eeaca1d1eaa96aa16ddb1176a9ffd65e3215004ab78f49981aaf1f) cannot be killed.\n",
      "Container has been successfully cleaned up.\n"
     ]
    }
   ],
   "source": [
    "# local deployment is working, it can be deleted now\n",
    "test_service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy as Webservice\n",
    "\n",
    "I deploy the model on an AzureContainerInstance with 1 CPU core with 1GB memory. I enabled authentification and app_insights for the WebService."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "gather": {
     "logged": 1635340260523
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2021-10-27 13:07:36+00:00 Creating Container Registry if not exists.\n",
      "2021-10-27 13:07:36+00:00 Registering the environment.\n",
      "2021-10-27 13:07:39+00:00 Use the existing image.\n",
      "2021-10-27 13:07:39+00:00 Generating deployment configuration.\n",
      "2021-10-27 13:07:41+00:00 Submitting deployment to compute.\n",
      "2021-10-27 13:07:44+00:00 Checking the status of deployment heart-failure-hyperdrive-service..\n",
      "2021-10-27 13:10:24+00:00 Checking the status of inference endpoint heart-failure-hyperdrive-service.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "aci_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1,\n",
    "                                                enable_app_insights=True,\n",
    "                                                auth_enabled=True)\n",
    "service = Model.deploy(workspace=ws,\n",
    "                       name=service_name,\n",
    "                       models=[model],\n",
    "                       inference_config=inference_config,\n",
    "                       deployment_config=aci_config,\n",
    "                       overwrite=True)\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The url for the swagger documentation of the REST Endpoint of this model can be found using the method `swagger_uri` of the Webservice object.\n",
    "To consume the model, I need the scoring uri and (since it is an ACI) a key to authentificate my request. I get those using the `scoring_uri`and `get_keys()` methods of the Webservice object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "gather": {
     "logged": 1635340291807
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://5515eba9-2ad1-4140-a95c-9655f98c2592.southcentralus.azurecontainer.io/score\n",
      "http://5515eba9-2ad1-4140-a95c-9655f98c2592.southcentralus.azurecontainer.io/swagger.json\n"
     ]
    }
   ],
   "source": [
    "# send request to deployed web service\n",
    "uri = service.scoring_uri\n",
    "print(uri)\n",
    "print(service.swagger_uri)\n",
    "key, _ = service.get_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "gather": {
     "logged": 1635340295512
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "headers[\"Authorization\"] = f\"Bearer {key}\"\n",
    "response = requests.post(uri, data=json.dumps(body), headers=headers)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Service Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.get_logs())\n",
    "service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submission Checklist**\n",
    "- I have registered the model.\n",
    "- I have deployed the model with the best accuracy as a webservice.\n",
    "- I have tested the webservice by sending a request to the model endpoint.\n",
    "- I have deleted the webservice and shutdown all the computes that I have used.\n",
    "- I have taken a screenshot showing the model endpoint as active.\n",
    "- The project includes a file containing the environment details.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
